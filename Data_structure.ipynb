{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diving deeper into the data structure\n",
    "\n",
    "This tutorial will give you a more in depth introduction of **deep**doctection's data model. This is helpful, if you want to introduce layout structures trained by new models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdoctection as dd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page and Image\n",
    "\n",
    "![page](./pics/dd_page_image.png)\n",
    "\n",
    "The `Page` object is a consumer class and a subclass of the `Image` object. The `Page` object simplifies the generic `Image` data class concept. It contains numerous attributes defined as `property` and thus represents a more content-driven view of the extracted data. For example, a `Page` contains `layouts`, `words` and `tables`. These concepts do not exist on the `Image` level.\n",
    "\n",
    "![image](./pics/dd_image.png)\n",
    "\n",
    "The `Image` object together with its `Annotation`s forms the **deep**doctection data model. All information that can be retrieved via the `Page` object is already in the `Image` object. `Image` has an attribute for saving `SummaryAnnotation`s. `SummaryAnnotation` is a class that allows you to store top level information of a document page (e.g. document type). \n",
    "Even more essential is the attribute `annotations`. This list saves all `ImageAnnotation`. Every instance from `Page.layouts`, `Page.words` or `Page.tables` is derived from an `ImageAnnotation` instance.\n",
    "\n",
    "Datasets used to train models or document pages processed through a pipeline are always passed in `Image` instances, never in `Page` instances. As said before, the `Page` instance only plays a role for the consumer who wants to have extracted information from a document page easily accessible. \n",
    "\n",
    "`ImageAnnotation` are objects that can be detected on a document page. This can be layout section (paragraphs, text blocks, image captions) or text lines or even words. `ImageAnnotation` have a `category_name`, `category_id` and an `annotation_id`. The `annotation_id` is the unique identifier for the instance. \n",
    "`ImageAnnotation` has a dict attribute `sub_categories`. Here, everything related to the `ImageAnnotation` can be stored. \n",
    "\n",
    "To have a practical example at hand, we use the JSON file we created in the [Get_Started notebook](./Analyzer_Get_Started.ipynb). You can find this JSON file in the sample folder of this repo as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/janis/Documents/Repos/notebooks/sample/test.json\"\n",
    "page = dd.Page.from_file(file_path=\"/home/janis/Documents/Repos/notebooks/sample/test.json\") # \"/path/to/dir/test.json\")\n",
    "\n",
    "image = page.image_orig # page instance keeps the original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Image` object has an `image_id` that uniquely defines the image object. Once the `Image` has been instantiated it will remain fix. \n",
    "\n",
    "On the other hand there is a `state_id` that changes once the whole `image` instance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id: 2aa98b36-196e-3cdf-af09-8f2d885d5f88 state_id: 98eebb5d-f319-3094-94af-fb0f02229dad\n"
     ]
    }
   ],
   "source": [
    "print(f\"image_id: {image.image_id} state_id: {image.state_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `word` object at the bottom from the **Get_Started** notebook. Having the `annotation_id` it is easy to find it among all other objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = page.get_annotation(annotation_ids='844631a5-5ddb-3ba8-b81a-bb9f05604d58')[0] # get_annotation returns a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a 1:1 correspondence between a `Layout`, `Word`, `Table`, `Cell` on the `Page` level and `ImageAnnotation` on the `Image` level. In fact, all layout sections are sub classes of `ImageAnnotation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepdoctection.datapoint.annotation.ImageAnnotation"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.__class__.__bases__[0].__bases__[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even retrieve the `ImageAnnotation` instance from which the `word` instance has been derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = image.get_annotation(annotation_ids='844631a5-5ddb-3ba8-b81a-bb9f05604d58')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories and keys are stored as members of special classes called ObjectTypes. \n",
    "It is not possible to define e.g. categories without assigning them to some ObjectTypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([<WordType.CHARACTERS>, <WordType.BLOCK>, <WordType.TEXT_LINE>, <Relationships.READING_ORDER>])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.sub_categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LayoutType.WORD>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.category_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ObjectTypes`\n",
    "\n",
    "`ObjectTypes` is a string based enum. For related keys or categories a subclass of `ObjectTypes` is formed. A `object_types_registry` is responsible for cataloging the `ObjectTypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DefaultType': <enum 'DefaultType'>,\n",
       " 'PageType': <enum 'PageType'>,\n",
       " 'SummaryType': <enum 'SummaryType'>,\n",
       " 'DocumentType': <enum 'DocumentType'>,\n",
       " 'LayoutType': <enum 'LayoutType'>,\n",
       " 'TableType': <enum 'TableType'>,\n",
       " 'CellType': <enum 'CellType'>,\n",
       " 'WordType': <enum 'WordType'>,\n",
       " 'TokenClasses': <enum 'TokenClasses'>,\n",
       " 'BioTag': <enum 'BioTag'>,\n",
       " 'TokenClassWithTag': <enum 'TokenClassWithTag'>,\n",
       " 'Relationships': <enum 'Relationships'>,\n",
       " 'Languages': <enum 'Languages'>,\n",
       " 'DatasetType': <enum 'DatasetType'>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.object_types_registry.get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordType.CHARACTERS\n",
      "WordType.BLOCK\n",
      "WordType.TOKEN_CLASS\n",
      "WordType.TAG\n",
      "WordType.TOKEN_TAG\n",
      "WordType.TEXT_LINE\n",
      "WordType.CHARACTER_TYPE\n",
      "WordType.PRINTED\n",
      "WordType.HANDWRITTEN\n"
     ]
    }
   ],
   "source": [
    "word = dd.object_types_registry.get(\"WordType\")\n",
    "for word_type in word:\n",
    "    print(word_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ImageAnnotation` and sub categories\n",
    "\n",
    "We have already mentioned that it is not directly possible to modify values and we do not recommmend modifying values as we are now going to describe how it can be done. We think however, it is worth to show you how it \n",
    "can be done theoretically, because it gives us the opportunity to explore the **deep**doctection data structure a bit more.\n",
    "\n",
    "`ImageAnnotation` and `CategoryAnnotation` can have sub categories. If available, they can be found by using the `get_sub_category` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContainerAnnotation(active=True, _annotation_id='ded39c8a-72c0-335b-853f-e6c8b50fbfbc', service_id=None, model_id=None, session_id=None, category_name=<WordType.CHARACTERS>, _category_name=<WordType.CHARACTERS>, category_id=-1, score=0.91, sub_categories={}, relationships={}, value='Gesamtverg√ºtung')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_ann = ann.get_sub_category(\"characters\")\n",
    "character_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside `ImageAnnotation` and `CategoryAnnotation` there is also a `ContainerAnnotation` class. It only differs from `CategoryAnnotation` by having an attribute `value` that can store a string or a value. It is now clear that all `Annotation` classes are dataclasses and therefore work as a storage. Having these at hand, we can now modify their values and these updates will persist!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_ann.value=\"Gesamtverg√ºtungsbericht\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.category_name=\"line\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned, `category_name` and sub category keys require values that are `ObjectTypes` members. If the value does not exist as\n",
    "registered `ObjectTypes` members an error is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'String headline does not correspond to a registered ObjectType'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mann\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcategory_name\u001B[49m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheadline\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Repos/deepdoctection_pt/deepdoctection/deepdoctection/datapoint/annotation.py:293\u001B[0m, in \u001B[0;36mCategoryAnnotation.category_name\u001B[0;34m(self, category_name)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"category name setter\"\"\"\u001B[39;00m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(category_name, \u001B[38;5;28mproperty\u001B[39m):\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_category_name \u001B[38;5;241m=\u001B[39m \u001B[43mget_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcategory_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Repos/deepdoctection_pt/deepdoctection/deepdoctection/utils/settings.py:414\u001B[0m, in \u001B[0;36mget_type\u001B[0;34m(obj_type)\u001B[0m\n\u001B[1;32m    412\u001B[0m return_value \u001B[38;5;241m=\u001B[39m _ALL_TYPES_DICT\u001B[38;5;241m.\u001B[39mget(obj_type)\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 414\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mString \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobj_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not correspond to a registered ObjectType\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m return_value\n",
      "\u001B[0;31mKeyError\u001B[0m: 'String headline does not correspond to a registered ObjectType'"
     ]
    }
   ],
   "source": [
    "ann.category_name=\"headline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an `ObjectTypes` with the required Enum member, registering and updating will then\n",
    "allow you to use this category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dd.object_types_registry.register(\"NewspaperType\")\n",
    "class NewspaperType(dd.ObjectTypes):\n",
    "\n",
    "    headline = \"headline\"\n",
    "    advertising = \"advertising\"\n",
    "    \n",
    "dd.update_all_types_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.category_name=\"headline\" # no key error anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding an `ImageAnnotation`\n",
    "\n",
    "Suppose, we want to add a new word to the page corpus. We have to define an `ImageAnnotation` and need to dump it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageAnnotation(active=True, _annotation_id=None, service_id=None, model_id=None, session_id=None, category_name=<LayoutType.WORD>, _category_name=<LayoutType.WORD>, category_id=-1, score=None, sub_categories={}, relationships={}, bounding_box=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ann = dd.ImageAnnotation(category_name=\"word\")\n",
    "new_ann  # No annotation_id has been assigned yet. This will happen once we dump the ImageAnnotation to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = dd.BoundingBox(absolute_coords=False, ulx=0.5,uly=0.7,lrx=0.6,lry=0.9) # setting up a bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ann.bounding_box = bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.dump(new_ann) # dump the annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageAnnotation(active=True, _annotation_id='0de5d9cf-f136-321d-b177-08c06157e600', service_id=None, model_id=None, session_id=None, category_name=<LayoutType.WORD>, _category_name=<LayoutType.WORD>, category_id=-1, score=None, sub_categories={}, relationships={}, bounding_box=BoundingBox(absolute_coords=False, ulx=0.5, uly=0.7, lrx=0.6, lry=0.9, height=0.20000000000000007, width=0.09999999999999998))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ann # There is an annotation_id available right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id: 2aa98b36-196e-3cdf-af09-8f2d885d5f88 state_id: b673b2b1-18c6-3b94-bbc1-14432b564ce4\n"
     ]
    }
   ],
   "source": [
    "print(f\"image_id: {image.image_id} state_id: {image.state_id}\") # state_id has changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a `ContainerAnnotation` to an `ImageAnnotation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_ann = dd.ContainerAnnotation(category_name=dd.WordType.CHARACTERS, value='Gesamtverg√ºtung')\n",
    "new_ann.dump_sub_category(dd.WordType.CHARACTERS, container_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageAnnotation(active=True, _annotation_id='0de5d9cf-f136-321d-b177-08c06157e600', service_id=None, model_id=None, session_id=None, category_name=<LayoutType.WORD>, _category_name=<LayoutType.WORD>, category_id=-1, score=None, sub_categories={<WordType.CHARACTERS>: ContainerAnnotation(active=True, _annotation_id='aafcb5b9-80ec-3bba-bd33-e93daac08c4d', service_id=None, model_id=None, session_id=None, category_name=<WordType.CHARACTERS>, _category_name=<WordType.CHARACTERS>, category_id=-1, score=None, sub_categories={}, relationships={}, value='Gesamtverg√ºtung')}, relationships={}, bounding_box=BoundingBox(absolute_coords=False, ulx=0.5, uly=0.7, lrx=0.6, lry=0.9, height=0.20000000000000007, width=0.09999999999999998))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ann # ContainerAnnotation is registered and added to ImageAnnotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub images from given `ImageAnnotation`\n",
    "\n",
    "In some situation we want to operate on a speicific part of the whole image that is defined by \n",
    "some `ImageAnnotation`. E.g. when building table recognition system, first we detect the table region, then we crop\n",
    "the table and perform cell/row/column detection on the sub image.\n",
    "\n",
    "We therefore need a simple way to convert an `ImageAnnotation` into a corresponding `Image` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.image_ann_to_image(annotation_id='844631a5-5ddb-3ba8-b81a-bb9f05604d58')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`image_ann_to_image` adds an `Image` object to the `ImageAnnotation` with `image_id` being the same as the `annotation_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image(file_name='sample_2.png', location='/home/janis/Public/notebooks/pics/samples/sample_2/sample_2.png', document_id='844631a5-5ddb-3ba8-b81a-bb9f05604d58', _image_id='844631a5-5ddb-3ba8-b81a-bb9f05604d58', embeddings={'844631a5-5ddb-3ba8-b81a-bb9f05604d58': BoundingBox(absolute_coords=True, ulx=0.0, uly=0.0, lrx=131.0, lry=15.0, height=15.0, width=131.0), '2aa98b36-196e-3cdf-af09-8f2d885d5f88': BoundingBox(absolute_coords=True, ulx=146.0, uly=1481.0, lrx=277.0, lry=1496.0, height=15.0, width=131.0)}, annotations=[])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = image.get_annotation(annotation_ids='844631a5-5ddb-3ba8-b81a-bb9f05604d58')[0]\n",
    "ann.image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also embedding bounding boxes that describe the relative position to the full image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(absolute_coords=True, ulx=146.0, uly=1481.0, lrx=277.0, lry=1496.0, height=15.0, width=131.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.image.get_embedding(image.image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a second bounding box that describes the position of the image in terms of its own coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(absolute_coords=True, ulx=0.0, uly=0.0, lrx=131.0, lry=15.0, height=15.0, width=131.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.image.get_embedding(ann.annotation_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `crop_image=True` will even store the pixel values of the sub image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.image_ann_to_image(annotation_id='844631a5-5ddb-3ba8-b81a-bb9f05604d58',crop_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7024cf50b0a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x1700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(ann.image.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<LayoutType.CELL>,\n",
       " <LayoutType.COLUMN>,\n",
       " <NewspaperType.headline>,\n",
       " <LayoutType.LIST>,\n",
       " <LayoutType.ROW>,\n",
       " <LayoutType.TABLE>,\n",
       " <LayoutType.TEXT>,\n",
       " <LayoutType.TITLE>,\n",
       " <LayoutType.WORD>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.get_categories_from_current_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd_pt_033",
   "language": "python",
   "name": "dd_pt_033"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
