{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/dd_logo.png) \n",
    "\n",
    "# Analyzer Configuration\n",
    "\n",
    "**deep**doctection's analyzer comes equipped with extensive configurations that allows:\n",
    "\n",
    "- to add and remove processing steps \n",
    "- to swap models for layout analysis or ocr\n",
    "- to adjust config setting for rule based processes\n",
    "- to configure the output structure\n",
    "\n",
    "In this notebook, we aim to take a closer look at the configuration and we will cover the most important features. \n",
    "\n",
    "We will assume familiarity with the [Get started notebook](./Analyzer_Get_Started.ipynb). If you want to understand the architecture of a pipeline we recommend having a look in the [pipeline notebook](./Pipelines.ipynb).\n",
    "\n",
    "## How to change configuration\n",
    "\n",
    "There are essentially two ways to adjust the configuration: by modifying the configuration file or by explicitly setting parameters.\n",
    "\n",
    "### Explicit parameter adjustment\n",
    "\n",
    "Pass the adjustments in a list:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T05:53:40.181930Z",
     "start_time": "2025-12-19T05:53:40.179729Z"
    }
   },
   "source": [
    "import deepdoctection as dd"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overwrite = [\"USE_TABLE_SEGMENTATION=False\",\n",
    "                    \"USE_OCR=False\",\n",
    "                    \"TEXT_ORDERING.BROKEN_LINE_TOLERANCE=0.01\",\n",
    "                    \"LAYOUT.FILTER=['title']\"]  # Make sure to include quotation marks around the string values \n",
    "#(e.g., ['title']), as omitting them may cause parsing errors. Do not leave any empty space, e.g. \"USE_TABLE_SEGMENTATION = False\"\n",
    "\n",
    "analyzer = dd.get_dd_analyzer(config_overwrite=config_overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration file\n",
    "\n",
    "**deep**doctection creates a cache directory the first time `dd.get_dd_analyzer()` is called. This cache directory stores all models and configurations that are used at any point in time. The configuration file can be found at `os.environ[\"DD_ONE_CONFIG\"]`. You can adjust the config file and load the new config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer(load_default_config_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify your own config file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer(path_config_file=\"path/to/your/config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High level Configuration\n",
    "\n",
    "The analyzer consists of various processing steps that can be switched on and off.\n",
    "\n",
    "```yaml\n",
    "# Enables the initial pipeline component using TesseractRotationTransformer to auto-rotate pages\n",
    "# by 90-degree increments. All subsequent components process the rotated page.\n",
    "USE_ROTATOR = False\n",
    "\n",
    "# Enables layout analysis component (second in the pipeline) for either full document layout analysis (DLA)\n",
    "# or single-object detection. Additional configurations via LAYOUT.*, LAYOUT.*, and ENFORCE_WEIGHTS.LAYOUT.\n",
    "USE_LAYOUT = True\n",
    "\n",
    "# Enables optional fine-grained Non-Maximum Suppression (NMS) after layout detection.\n",
    "# Configure via LAYOUT_NMS_PAIRS.* settings.\n",
    "USE_LAYOUT_NMS = True\n",
    "\n",
    "# Enables table segmentation (third and later pipeline components).\n",
    "# Applies row/column detection, optional cell detection, and segmentation services.\n",
    "# Configure sub-services via ITEM.*, ITEM.*, CELL.*, CELL.*, and SEGMENTATION.*\n",
    "USE_TABLE_SEGMENTATION = True\n",
    "\n",
    "# Enables optional refinement of table structure to ensure valid HTML generation.\n",
    "# Should be set to False when using the TableTransformer models: \n",
    "# ITEM.WEIGHTS = deepdoctection/tatr_tab_struct_v2/model.safetensors\n",
    "USE_TABLE_REFINEMENT = False\n",
    "\n",
    "# Enables text extraction using PDFPlumber. Only works on PDFs with embedded text layers.\n",
    "# Configure additional behavior using PDF_MINER.*\n",
    "USE_PDF_MINER = False\n",
    "\n",
    "# Enables OCR functionality using Tesseract, DocTr, or Textract.\n",
    "# Also activates MatchingService and TextOrderingService to associate text with layout elements.\n",
    "# Further configurations via OCR.*, WORD_MATCHING.*, TEXT_CONTAINER, and TEXT_ORDERING.*\n",
    "USE_OCR = True\n",
    "\n",
    "# Enables MatchingService to associate nearby layout elements (e.g., figures and captions).\n",
    "USE_LAYOUT_LINK = False\n",
    "\n",
    "# Enables line matching in post-processing. Useful when synthetic line elements are created\n",
    "# (e.g., by grouping orphan text containers). Only applicable if list items were previously grouped.\n",
    "USE_LINE_MATCHER = False\n",
    "\n",
    "# Enables a sequence classification pipeline component, e.g. a LayoutLM or a Bert-like model.\n",
    "USE_LM_SEQUENCE_CLASS = False\n",
    "\n",
    "# Enables a token classification pipeline component, e.g. a LayoutLM or Bert-like model\n",
    "USE_LM_TOKEN_CLASS = False\n",
    "```\n",
    "\n",
    "## Rotator models\n",
    "\n",
    "There are two approaches available: One that uses `Tesseract` and a second method based on `DocTr`. Set `ROTATOR.MODEL=tesseract` or  \n",
    "`ROTATOR.MODEL=doctr`. \n",
    "\n",
    "## Layout models\n",
    "\n",
    "Once `USE_LAYOUT=True` you can configure the layout pipeline component further. You can choose between `layout/d2_model_0829999_layout_inf_only.pt`, `microsoft/table-transformer-detection/model.safetensors` or you can keep the default model `Aryn/deformable-detr-DocLayNet/model.safetensors`. These model are members of a model registry which is why they are easy to use. \n",
    "\n",
    "Note, the these models have been trained on different datasets and will therefore vary in accuracy depending on your use-case.\n",
    "\n",
    "Use `layout/d2_model_0829999_layout_inf_only.pt` for scientific articles, `microsoft/table-transformer-detection/model.safetensors` if you are only interested in table detection. `Aryn/deformable-detr-DocLayNet/model.safetensors` is more general and can be used for financial reports, patents, manuals or laws and regulation documents.\n",
    "\n",
    "You can also add some custom models as well, but this requires to add them to the model registry and maybe, you need to write a **deep**doctection wrapper.\n",
    "\n",
    "## Layout Non-Maximum-Supression\n",
    "\n",
    "This is relevant if `USE_LAYOUT_NMS=True`.\n",
    "\n",
    "Layout models often produce overlapping layout sections. These can be removed using Non-Maximum Suppression (NMS). \n",
    "Suppose a large and complex table is detected — it's not uncommon for a text block or a title to be mistakenly recognized within the table as well, potentially even with a high confidence score. In such cases, you may still want to retain the table at all costs.\n",
    "\n",
    "Using the `LAYOUT_NMS_PAIRS` configuration, you can define pairs of layout sections that should be subjected to NMS once a certain overlap threshold is exceeded. Additionally, you can set a priority to specify which category should be favored when overlaps occur.\n",
    "\n",
    "In `.yaml`-terms, the configuration consists of three parts:\n",
    "\n",
    "```yaml\n",
    "LAYOUT_NMS_PAIRS:\n",
    "  COMBINATIONS:  # Pairs of layout categories to be checked for NMS\n",
    "    - - table\n",
    "      - title\n",
    "  PRIORITY:  # Preferred category when overlap occurs. If set to `None`, NMS uses the confidence score.\n",
    "    - table\n",
    "  THRESHOLDS:  # IoU overlap threshold. Pairs with lower IoU will be ignored.\n",
    "    - 0.001\n",
    "```\n",
    "\n",
    "Using Python, the config looks as follows:\n",
    "\n",
    "```python\n",
    "config_overwrite=[\"LAYOUT_NMS_PAIRS.COMBINATIONS=['table','title']\",\n",
    "                  \"LAYOUT_NMS_PAIRS.PRIORITY=['table']\",\n",
    "                  \"LAYOUT_NMS_PAIRS.THRESHOLDS=[0.001]\"]\n",
    "```\n",
    "\n",
    "This allows fine-grained control over which layout sections should be retained and which should be suppressed during postprocessing.\n",
    "\n",
    "## Table segmentation models\n",
    "\n",
    "To infer rows, columns, simple and multi spanning cells of a detected table layout segment, a segmentation step is required. Once `USE_TABLE_SEGMENTATION=True` is set: **deep**doctection provides two approaches that depend on the choice of the model.\n",
    "\n",
    "### [Table transformer](https://github.com/microsoft/table-transformer)\n",
    "\n",
    "This is the default setting and the most general approach.\n",
    "\n",
    "```python\n",
    "config_overwrite=[\"ITEM.WEIGHTS=deepdoctection/tatr_tab_struct_v2/model.safetensors\"]\n",
    "```\n",
    "\n",
    "We have observed that the recognition of multi-spanning cells is **less reliable** for non-scientific tables. If multi-spanning cells or headers are not essential, we recommend filtering them out. The result is a table structure consisting only of simple cells, i.e., cells with `row_span=1` and `column_span=1`.\n",
    "\n",
    "### Filtering Redundant Detections\n",
    "\n",
    "The Table Transformer may detect redundant table structures and headers. To filter those out, apply the following:\n",
    "\n",
    "```yaml\n",
    "ITEM:\n",
    "   WEIGHTS: microsoft/table-transformer-structure-recognition/pytorch_model.bin\n",
    "   FILTER:\n",
    "      - table\n",
    "      - column_header\n",
    "      - projected_row_header\n",
    "      - spanning\n",
    "```\n",
    "\n",
    "This ensures that only relevant cell structures are retained, improving clarity and reducing noise in the segmentation output.\n",
    "\n",
    "\n",
    "### deepdoctection's built-in approach\n",
    "\n",
    "```python\n",
    "config_overwrite=[\"ITEM.WEIGHTS=item/d2_model_1639999_item_inf_only.pt\",\n",
    "                  \"CELL.WEIGHTS=cell/d2_model_1849999_cell_inf_only.pt\"]\n",
    "```\n",
    "\n",
    "These models have been trained on scientific reports and are more specialized. \n",
    "\n",
    "`USE_TABLE_REFINEMENT=True` will improve the table structure but only works in conjunction with **deep**doctection's built-in approach.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "The segmentation configuration is extensive, and we cannot cover every setting in detail. For a comprehensive description of all parameters, we refer to the source code. We will focus on the parameters that have the most significant impact on the segmentation results.\n",
    "\n",
    "\n",
    "```python\n",
    "# Specifies the rule used to assign detected cells to rows and columns.\n",
    "# Can be either 'iou' (Intersection over Union) or 'ioa' (Intersection over Area).\n",
    "# In the Table Transformer approach, this also applies to special cell types like spanning or header cells.\n",
    "SEGMENTATION.ASSIGNMENT_RULE = \"ioa\"\n",
    "\n",
    "# Threshold for assigning a (special) cell to a row based on the chosen rule (IOU or IOA).\n",
    "# The row assignment is based on the highest-overlapping row.\n",
    "# Multiple overlaps can lead to increased rowspan.\n",
    "SEGMENTATION.THRESHOLD_ROWS = 0.4\n",
    "\n",
    "# Threshold for assigning a (special) cell to a column based on the chosen rule (IOU or IOA).\n",
    "# The column assignment is based on the highest-overlapping column.\n",
    "SEGMENTATION.THRESHOLD_COLS = 0.4\n",
    "\n",
    "# Removes overlapping rows based on an IoU threshold.\n",
    "# Helps to prevent multiple row spans caused by overlapping detections.\n",
    "# Note: for better alignment, SEGMENTATION.FULL_TABLE_TILING can be enabled.\n",
    "# Using a low threshold here may result in a very coarse grid.\n",
    "SEGMENTATION.REMOVE_IOU_THRESHOLD_ROWS = 0.2\n",
    "\n",
    "# Same as above, but applied to columns.\n",
    "SEGMENTATION.REMOVE_IOU_THRESHOLD_COLS = 0.2\n",
    "\n",
    "# Ensures that predicted rows and columns fully cover the table region.\n",
    "# When enabled, rows will be stretched horizontally and vertically to fit the full region.\n",
    "# For rows, the first row will be stretched to the top, and the space to the second row is used to estimate the\n",
    "# bottom edge. This rule applies similarly to columns.\n",
    "SEGMENTATION.FULL_TABLE_TILING = True\n",
    "\n",
    "# Defines how row and column boundaries are stretched when tiling is enabled.\n",
    "# Options:\n",
    "# - \"left\": lower edge equals the upper edge of the next row\n",
    "# - \"equal\": lower edge is halfway between two adjacent rows\n",
    "SEGMENTATION.STRETCH_RULE = \"equal\"\n",
    "\n",
    "# Defines the threshold values for matching column/row header cells to their respective rows/columns\n",
    "# in the Table Transformer approach. The matching rule is defined in SEGMENTATION.ASSIGNMENT_RULE.\n",
    "SEGMENTATION.PUBTABLES_ITEM_HEADER_THRESHOLDS = [0.6, 0.0001]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Text extraction\n",
    "\n",
    "There are two ways to extract text:\n",
    "\n",
    "- If the document is a PDF one can try to extract the text from its text layer. This requires native PDF documents where the text can be extracted from the byte encoding.\n",
    "- Running OCR.\n",
    "\n",
    "### PDFPlumber\n",
    "\n",
    "To activate the PDF miner:\n",
    "\n",
    "```yaml\n",
    "USE_PDF_MINER: True\n",
    "```\n",
    "\n",
    "PDF Miners need to group character like objects into words. This task is rule based and can be further customized:\n",
    "\n",
    "```python\n",
    "# Horizontal tolerance when merging characters into words.\n",
    "# Characters that are horizontally closer than this value will be grouped into a single word.\n",
    "PDF_MINER.X_TOLERANCE=3\n",
    "\n",
    "# Vertical tolerance when grouping characters into lines.\n",
    "# Characters within this vertical range will be considered part of the same line.\n",
    "PDF_MINER.Y_TOLERANCE=3\n",
    "```\n",
    "\n",
    "### OCR\n",
    "\n",
    "There are three are all OCR engines available.\n",
    "\n",
    "```yaml\n",
    "OCR:\n",
    "  USE_TESSERACT: False\n",
    "  USE_DOCTR: True\n",
    "  USE_TEXTRACT: False\n",
    "```\n",
    "\n",
    "**To activate one OCR engine, you also must ensure to deactivate the other two.**\n",
    "\n",
    "\n",
    "#### DocTr\n",
    "\n",
    "DocTr is a powerful library that provides small but very efficient models. What makes it particularly valuable is that it includes training scripts and allows models to be trained with custom vocabularies. This makes it possible to build OCR models for highly specialized scripts where standard OCR solutions easily fail.\n",
    "\n",
    "A DocTr OCR pipeline consists of two steps: spatial word detection and character recognition within the region of interest.\n",
    "\n",
    "For word detection, there is currently one model available:\n",
    "\n",
    "```python\n",
    "OCR.WEIGHTS.DOCTR_WORD=\"doctr/db_resnet50/db_resnet50-ac60cadc.pt\"\n",
    "```\n",
    "\n",
    "For text recognition, the default model is:\n",
    "\n",
    "```python\n",
    "OCR.WEIGHTS.DOCTR_RECOGNITION=\"doctr/crnn_vgg16_bn/crnn_vgg16_bn-0417f351.pt\"\n",
    "```\n",
    "\n",
    "but you can also use: \n",
    "\n",
    "\n",
    " * `Felix92/doctr-torch-parseq-multilingual-v1/pytorch_model.bin`\n",
    " * `doctr/crnn_vgg16_bn/pt/master-fde31e4a.pt`\n",
    "\n",
    "\n",
    "#### Tesseract\n",
    "\n",
    "```yaml\n",
    "OCR:\n",
    "  USE_TESSERACT: True\n",
    "  USE_DOCTR: False\n",
    "  USE_TEXTRACT: False\n",
    "```\n",
    "\n",
    "In addition to DocTr, Tesseract is arguably the most widely known open-source OCR solution and provides pre-trained models for a large number of languages. However, Tesseract must be installed separately. We refer to the official Tesseract documentation.\n",
    "\n",
    "Tesseract comes with its own configuration file, which is located alongside other configuration files under `~/.cache/deepdoctection/configs/dd/conf_dd_one.yaml`. \n",
    "\n",
    "\n",
    "#### AWS Textract\n",
    "\n",
    "Textract is the AWS OCR solution that can be accessed via API. It is superior to many Open Source solutions. This is a paid service and requires an AWS account. You also need to install `boto3`. We refer to the official documentation to access the service via API.\n",
    "\n",
    "To use the API, credentials must be provided. You can use the AWS CLI with its built-in secret management or use an `.env` file with\n",
    "\n",
    "```\n",
    "AWS_ACCESS_KEY_ID=your-aws-key\n",
    "AWS_SECRET_ACCESS_KEY=your-secret-key\n",
    "AWS_REGION=your-region\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "The following two pipeline configuration will automatically be effective once you set `USE_OCR=True` or `USE_PDF_MINER=True`.\n",
    "\n",
    "\n",
    "\n",
    "## Word matching\n",
    "\n",
    "Word matching serves to merge the results of layout analysis (including table structure) with those of OCR (words and maybe lines). Up to this point, all layout segments and words are independent elements of a page, with no established relationships between them. Word matching creates a link between each word and the appropriate layout segment.\n",
    "\n",
    "The most effective way to establish this link is by evaluating the spatial overlap between a word and layout sections. It must be specified which layout sections are eligible for such associations — not all segments are suitable. For example, words that are part of a table should not be linked to the table's outer frame, but rather to the individual cell identified during table segmentation.\n",
    "\n",
    "The following configuration uses a class `IMAGE_DEFAULTS` that contains default values for the word matching.\n",
    "Depending on which OCR engine is used, some return text and bounding boxes on word level, while others return text on text line level with bounding boxes. `IMAGE_DEFAULTS.TEXT_CONTAINER` is therefore the element, that contain the lowest level text elements. The default value is `word`.\n",
    "\n",
    "```python\n",
    "# Specifies the annotation type used as a text container.\n",
    "# A text container is typically an ImageAnnotation generated by the OCR engine or PDF mining tool.\n",
    "# It contains a sub-categories of type `characters`.\n",
    "# Most commonly, text containers are of type `word`, but `line` may also be used.\n",
    "# It is recommended to align this value with IMAGE_DEFAULTS.TEXT_CONTAINER\n",
    "# rather than modifying it directly in the config.\n",
    "TEXT_CONTAINER = IMAGE_DEFAULTS.TEXT_CONTAINER\n",
    "\n",
    "# Configuration for matching text containers (e.g., words or lines) to layout elements\n",
    "# such as titles, paragraphs, tables, etc., using spatial overlap.\n",
    "# When a match occurs, a parent-child relationship (Relationships.CHILD) is assigned.\n",
    "\n",
    "# Specifies the layout categories considered as potential parents of text containers.\n",
    "WORD_MATCHING.PARENTAL_CATEGORIES = IMAGE_DEFAULTS.TEXT_BLOCK_CATEGORIES\n",
    "\n",
    "# Rule used for matching: either 'iou' (intersection over union) or 'ioa' (intersection over area).\n",
    "WORD_MATCHING.RULE = \"ioa\"\n",
    "\n",
    "# Threshold for the selected matching rule (IOU or IOA).\n",
    "# Text containers must exceed this threshold to be assigned to a layout section.\n",
    "WORD_MATCHING.THRESHOLD = 0.3\n",
    "\n",
    "# If a text container overlaps with multiple layout sections,\n",
    "# setting this to True will assign it only to the best-matching (i.e., highest-overlapping) section.\n",
    "# Prevents duplication of text in the output.\n",
    "WORD_MATCHING.MAX_PARENT_ONLY = True\n",
    "```\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reading Order\n",
    "\n",
    "Next, words and layout segments must be arranged to form coherent, continuous text. This task is handled by the `TextOrderService` component.\n",
    "\n",
    "As already mentioned in several occasions, establishing a reading order is a sophisticated task. This becomes even more true, if the document has a complex layout structure, with a lot of different elements.\n",
    "\n",
    "When thinking about getting some sort of narrative text, you first need to think what layout sections need have to be part of that narrative text.\n",
    "This depends on the layout sections being extracted and eventually depends on the layout model.\n",
    "\n",
    "Layout sections of narrative text are given by `IMAGE_DEFAULT.FLOATING_TEXT_BLOCK_CATEGORIES` and its default is given by:\n",
    "\n",
    "```python\n",
    "IMAGE_DEFAULT.FLOATING_TEXT_BLOCK_CATEGORIES=['text,'title','list','key_value_area']\n",
    "```\n",
    "\n",
    "Beside narrative text, you need to specify which layout sections actually may contain text. This is a result from word matching and is given by `IMAGE_DEFAULTS.TEXT_BLOCK_CATEGORIES`.\n",
    "\n",
    "```python\n",
    "IMAGE_DEFAULT.TEXT_BLOCK_CATEGORIES=['text,'title','list_item','list', 'caption', page_header',\n",
    "                                      'page_footer', 'page_number', 'mark', 'key_value_area',\n",
    "                                      'figure', 'spanning', 'cell']\n",
    "```\n",
    "\n",
    "Using the terminology of `IMAGE_DEFAULTS`:\n",
    "\n",
    "- `IMAGE_DEFAULTS.TEXT_CONTAINER`, that have been assigned to some `IMAGE_DEFAULT.TEXT_BLOCK_CATEGORIES` will be ordered within it text blocks.\n",
    "- `IMAGE_DEFAULT.FLOATING_TEXT_BLOCK_CATEGORIES`, which should be in general a subset of `IMAGE_DEFAULT.TEXT_BLOCK_CATEGORIES` will be ordered to generate the narrative text of the page document. We are not going into more detail here, how the ordering works in detail. For further details on layout parsing and text ordering, please refer to the [**documentation**](https://deepdoctection.readthedocs.io/en/latest/tutorials/layout_parsing_structure).\n",
    "\n",
    "```python\n",
    "\n",
    "# Specifies which layout categories must be ordered (e.g., paragraphs, list items).\n",
    "# These are layout blocks that will be processed by the TextOrderingService.\n",
    "cfg.TEXT_ORDERING.TEXT_BLOCK_CATEGORIES = IMAGE_DEFAULTS.TEXT_BLOCK_CATEGORIES\n",
    "\n",
    "# Specifies which text blocks are considered floating (not aligned with strict columns or grids).\n",
    "# These will be linked with a subcategory of type Relationships.READING_ORDER.\n",
    "cfg.TEXT_ORDERING.FLOATING_TEXT_BLOCK_CATEGORIES = IMAGE_DEFAULTS.FLOATING_TEXT_BLOCK_CATEGORIES\n",
    "\n",
    "# In the word matching process it is possible that some words do not overlap with any layout segment.\n",
    "# If `INCLUDE_RESIDUAL_TEXT_CONTAINER` is set to `False`, these words will not receive a `reading_order` and will be excluded from the text output.\n",
    "# If set to `True`, orphan words are grouped into `line`s and included in the output, ensuring no text is lost. This setting is often crucial and may\n",
    "# need to be adjusted depending on your use case.\n",
    "cfg.TEXT_ORDERING.INCLUDE_RESIDUAL_TEXT_CONTAINER = True\n",
    "\n",
    "# Tolerance used to determine whether a text block's left/right coordinate lies within a column’s boundary.\n",
    "# Helps with assigning text blocks to columns based on horizontal alignment.\n",
    "cfg.TEXT_ORDERING.STARTING_POINT_TOLERANCE = 0.005\n",
    "\n",
    "# Horizontal distance threshold for grouping words into the same line.\n",
    "# If the gap between words exceeds this value, they will be treated as belonging to separate lines or columns.\n",
    "cfg.TEXT_ORDERING.BROKEN_LINE_TOLERANCE = 0.003\n",
    "\n",
    "# Used for ordering vertically broken floating text blocks into coherent columns.\n",
    "# Defines vertical alignment tolerance between adjacent text blocks.\n",
    "cfg.TEXT_ORDERING.HEIGHT_TOLERANCE = 2.0\n",
    "\n",
    "# Defines the spacing threshold that indicates a paragraph break in vertically arranged text blocks.\n",
    "# Helps determine reading order in multi-column, broken layouts.\n",
    "cfg.TEXT_ORDERING.PARAGRAPH_BREAK = 0.035\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd-1.0",
   "language": "python",
   "name": "dd-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
