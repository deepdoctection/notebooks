{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/dd_logo.png) \n",
    "\n",
    "# Getting started\n",
    "\n",
    "**deep**doctection is a package that can be used to extract text from complex structured documents. It also allows to run multi-modal models (text+vision) in an end-to end pipeline. Inputs can be native PDFs or images. In contrast to various text miners **deep**doctection makes use of deep learning models from powerful third party libraries solving OCR, vision or classification or entity recognition problems. It is very versatile.\n",
    "\n",
    "This notebook will give you a quick introduction to show you, how you can use **deep**doctection for extracting text information from complex documents. \n",
    "\n",
    "We assume that you have successfully installed **deep**doctection with Tensorflow or Pytorch extension and that you can run Tesseract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import deepdoctection as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample\n",
    "\n",
    "Take an image (e.g. .png, .jpg, ...). If you take the example below you'll maybe need to change ```image_path```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path.cwd() / \"pics/samples/sample_2/sample_2.png\"\n",
    "image = cv2.imread(image_path.as_posix())\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/samples/sample_2/sample_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer\n",
    "\n",
    "Next, we instantiate the **deep**doctection analyzer. The analyzer is an example of a pipeline that can be built depending on the problem you want to tackle. This particular pipeline is built from various building blocks. We will come back to this later. \n",
    "\n",
    "Because the document is german we will be using Tesseract's model trained on german text (config_overwrite=[\"LANGUAGE='deu'\"]). If you have a document in a different language choose one by entering its [LangCode](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html). Here are some examples: `fra`, `nld`, `chi_sim`, `ces`, `fas`, `ell`, `mkd`, `ron`, `hye`, `kat`. \n",
    "\n",
    "This will give you, depending on your language, much better results than using the default english model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer(config_overwrite=[\"LANGUAGE='deu'\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze methods\n",
    "\n",
    "Once all models have been loaded, we can process single pages, multi page PDF-documents or `Dataflow`s. Leaving `Dataflow`s aside for now, you can either set `path='path/to/dir'` if you have a folder of images or `path='path/to/my/doc.pdf'` if you have a pdf document. \n",
    "\n",
    "You will receive an error if your path points to a single image. Processing images requires to pass the path to the base image directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|                                                                                                                                                                                                                                                                                                                                  |1/?[00:00<00:00,1439.86it/s]\n"
     ]
    }
   ],
   "source": [
    "path = Path.cwd() / \"pics/samples/sample_2\"\n",
    "\n",
    "df = analyzer.analyze(path=path)\n",
    "df.reset_state()  # This method must be called just before starting the iteration. It is part of the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see, when activating the cell, that not much has happened yet. The reason is that `analyze` is a [generator function](https://wiki.python.org/moin/Generators). It does not return instantly any results. Instead it returns a `Dataflow`. \n",
    "\n",
    "A `Dataflow` is an object to create iterators for data loading and data processing. You can traverse through all the values of the `Dataflow` simply by using a `for`-loop or the `next` function. Let's go!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=iter(df)\n",
    "page = next(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page\n",
    "\n",
    "Let's see what we got back. For each iteration we receive a `Page` object. This object stores all informations that have been collected from a page document when running through the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepdoctection.datapoint.view.Page"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also have a look on some top level information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " height: 2339.0 \n",
      " width: 1654.0 \n",
      " file_name: sample_2.png \n",
      " document_id: d0e3f4cc-f604-3f08-9dc6-95c04bb6c51b \n",
      " image_id: d0e3f4cc-f604-3f08-9dc6-95c04bb6c51b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\" height: {page.height} \\n width: {page.width} \\n file_name: {page.file_name} \\n document_id: {page.document_id} \\n image_id: {page.image_id}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`document_id` and `image_id` are the same. The reason is because we only process a single image. The naming convention silently assumes that we deal with a one page document. Once we process multi page PDFs `document_id` and `image_id` differ.\n",
    "\n",
    "With `get_attribute_names()` you get a list of all attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<PageType.ANGLE>,\n",
       " 'chunks',\n",
       " 'document_id',\n",
       " <PageType.DOCUMENT_TYPE>,\n",
       " 'file_name',\n",
       " <PageType.LANGUAGE>,\n",
       " 'layouts',\n",
       " 'location',\n",
       " 'page_number',\n",
       " 'tables',\n",
       " 'text',\n",
       " 'words'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.get_attribute_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.document_type, page.language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`page.document_type` and `page.language` both return None. The reason is that the analyzer has no component for predicting a document type or a language.\n",
    "\n",
    "You can easily build a custom analyzer/pipeline containing a document classifier, though. Check this [notebook](Using_LayoutLM_for_sequence_classification.ipynb) for further information.\n",
    "\n",
    "## Layout segments\n",
    "\n",
    "We can visualize detected layout segments. If you set `interactive=True` a viewer will pop up. Use `+` and `-` to zoom out/in. Use `q` to close the page.\n",
    "\n",
    "Alternatively, you can visualize the output with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = page.viz()\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/output_16_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at other attributes. We can use the `text` property to get the content of the document. You will notice that the table is not included. You can therefore filter tables from the other content. In fact you can even filter on every layout segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Festlegung der VV und angemessene Risikoadjustierung\n",
      "Die VV-Pools der DWS Gruppe werden einer angemessenen Anpassung der Risiken unterzogen, die die Adjustierung ex ante als auch ex post umfasst. Die angewandte robuste Methode soll sicherstellen, dass bei der Festlegung der VV sowohl der risikoadjustierten Leistung als auch der Kapital- und Liquiditätsausstattung der DWS Gruppe Rechnung getragen wird. Die Er- mittlung des Gesamtbetrags der VV orientiert sich primär an (i) der Tragfähigkeit für die DWS Gruppe (das heißt, was „kann” die DWS Gruppe langfristig an VV im Einklang mit regulatorischen ‚Anforderungen gewähren) und (il) der Leistung (das heißt, was „sollte” die DWS Gruppe an VV gewähren, um für eine angemessene leistungsbezogene Vergütung zu sorgen und gleichzeitig den langfristigen Erfolg des Unternehmens zu sichern)\n",
      "Die DWS Gruppe hat für die Festlegung der VV auf Ebene der individuellen Mitarbeiter die „Grundsätze für die Festlegung der variablen Vergütung” eingeführt. Diese enthalten Informationen über die Faktoren und Messgrößen, die bei Entscheidungen zur IVV berücksichtigt werden müssen. Dazu zählen beispielsweise Investmentperformance, Kundenbindung, Erwägungen zur Unternehmenskultur sowie Zielvereinbarungen und Leistungsbeurteilung im Rahmen des „Ganzheitliche Leistung“-Ansatzes. Zudem werden Hinweise der Kontrollfunktionen und Diszipli- narmaßnahmen sowie deren Einfluss auf die VV einbezogen\n",
      "Bei per Ermessensentscheidung erfolgenden Sub-Pool-Zuteilungen verwendet das DWS DCC die internen (finanziellen und nichtfinanziellen) Balanced Scorecard-Kennzahlen zur Erstellung differenzierter und leistungsbezogener VV-Pools,\n",
      "Vergütung für das Jahr 2018\n",
      "Nach der hervorragenden Entwicklung im Jahr 2017 hatte die globale Vermögensverwaltungsbranche 2018 mit einigen Schwierigkeiten zu kämpfen. Gründe waren ungünstige Marktbedin- gungen, stärkere geopolitische Spannungen und die negative Stimmung unter den Anlegern, vor allem am europäischen Retail-Miarkt. Auch die DWS Gruppe blieb von dieser Entwicklung nicht verschont.\n",
      "Vor diesem Hintergrund hat das DCC die Tragfähigkeit der VV für das Jahr 2018 kontrolliert und festgestellt, dass die Kapital- und Liquiditätsausstattung der DWS Gruppe unter Berücksichti- ‚gung des Ergebnisses vor und nach Steuern klar über den regulatorisch vorgeschriebenen Mindestanforderungen und dem internen Schwellenwert für die Risikotoleranz liegt.\n",
      "Als Teil der im März 2019 für das Performance-Jahr 2018 gewährten VV wurde die Gruppenkomponente allen berechtigten Mitarbeitern auf Basis der Bewertung der vier festgelegten Leistungs- kennzahlen gewährt. Der Vorstand der Deutsche Bank AG hat für 2018 unter Berücksichtigung der beträchtlichen Leistungen der Mitarbeiter und in seinem Ermessen einen Zielerreichungsgrad von 70 % festgelegt\n",
      "Identifi ierung von Risikoträgern\n",
      "Gemäß Gesetz vom 17. Dezember 2010 über die Organismen für gemeinsame Anlagen (in seiner jeweils gültigen Fassung) sowie den ESMA-Leitlinien unter Berücksichtigung der OGAW- Richtlinie hat die Gesellschaft Mitarbeiter mit wesentlichem Einfluss auf das Risikoprofil der Gesellschaft ermittelt („Risikoträger\"). Das Identifizierungsverfahren basiert auf der Bewertung des Einflusses folgender Kategorien von Mitarbeitern auf das Risikoprofil der Gesellschaft oder einen von ihr verwalteten Fonds: (a) Geschäftsführung/Senior Management, (b) Portfolio-/ Investmentmanager, (c) Kontrollfunktionen, (d) Mitarbeiter mit Leitungsfunktionen in Verwaltung, Marketing und Human Resources, (e) sonstige Mitarbeiter (Risikoträger) mit wesentlichem Einfluss, (f} sonstige Mitarbeiter in der gleichen Vergütungsstufe wie sonstige Risikoträger. Mindestens 40 % der VV für Risikoträger werden aufgeschoben vergeben. Des Weiteren werden für wichtige Anlageexperten mindestens 50 % sowohl des direkt ausgezahlten als auch des aufgeschobenen Teils in Form von aktienbasierten oder fondsbasierten Instrumenten der DWS Gruppe gewährt. Alle aufgeschobenen Komponenten sind bestimmten Leistungs- und Verfallbedingungen unterworfen, um eine angemessene nachträgliche Risikoadjustierung zu gewähr- leisten. Bei einem VV-Betrag von weniger als EUR 50.000 erhalten Risikoträger ihre gesamte \\VV in bar und ohne Aufschub.\n",
      "Zusammenfassung der Informationen zur Vergütung für die Gesellschaft für 2018 '\n",
      "\\ Vergütungsdaten für Delegierte, die die Gesellschaft Portfolio- oder Risikomanagementaufgaben übertragen hat, sind nicht der Tabelle erfasst. an in Unter Berücksichtigung diverser Vergütungsbestandteile entsprechend den Definitionen in den ESMA-Leitlinien, die Geldzahlungen oder leistungen (wie Bargeld, Anteile, Optionsscheine, Rentenbeiträge) oder Nicht-(direkte) Geldleistungen (wie Gehaltsnebenleistungen oder Sondervergütungen für Fahrzeuge, Mobiltelefone, usw.) umfassen 3 „Senior Management” umfasst nur den Vorstand der Gesellschaft. Der Vorstand erfüllt die Definition als Führungskräfte der Gesellschaft. Uber den Vorstand hinaus wurden keine weiteren Führungskräfte identifiziert.\n"
     ]
    }
   ],
   "source": [
    "print(page.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the individual layout segments like `text`, `title`, `list` or `figure`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Identifi ierung von Risikoträgern\n",
      "Title: Vergütung für das Jahr 2018\n",
      "Title: Festlegung der VV und angemessene Risikoadjustierung\n"
     ]
    }
   ],
   "source": [
    "for layout in page.layouts:\n",
    "    if layout.category_name==\"title\":\n",
    "        print(f\"Title: {layout.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the layout segments from the `chunks` attribute. The output is a list of tuples with the most essential meta data for each layout segment, namely: `document_id, image_id, page_number, annotation_id, reading_order, category_name` and `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('d0e3f4cc-f604-3f08-9dc6-95c04bb6c51b',\n",
       " 'd0e3f4cc-f604-3f08-9dc6-95c04bb6c51b',\n",
       " 0,\n",
       " '47673133-ec40-3ef8-ad94-8549fe9eb0af',\n",
       " 1,\n",
       " <LayoutType.TITLE>,\n",
       " 'Festlegung der VV und angemessene Risikoadjustierung')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables cannot be retrieved from `page.layouts`. They have a special `page.tables` which is a python list of table objects. Obviously, only one table has been detected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page.tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox',\n",
       " 'cells',\n",
       " 'columns',\n",
       " 'csv',\n",
       " <TableType.HTML>,\n",
       " <TableType.ITEM>,\n",
       " <TableType.MAX_COL_SPAN>,\n",
       " <TableType.MAX_ROW_SPAN>,\n",
       " 'np_image',\n",
       " <TableType.NUMBER_OF_COLUMNS>,\n",
       " <TableType.NUMBER_OF_ROWS>,\n",
       " <Relationships.READING_ORDER>,\n",
       " 'rows',\n",
       " 'text',\n",
       " 'words'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = page.tables[0]\n",
    "table.get_attribute_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " number of rows: 8 \n",
      " number of columns: 2 \n",
      " reading order: None\n"
     ]
    }
   ],
   "source": [
    "print(f\" number of rows: {table.number_of_rows} \\n number of columns: {table.number_of_columns} \\n reading order: {table.reading_order}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no reading order. The reason is that we have excluded tables from having a specific reading order position because we want to separate tables from the narrative text. This is pure customizing and we can change the customizing so that tables are part of the narrative text. We will come to this later.\n",
    "\n",
    "You can get an html, csv or text version of your table. Use `table.csv` to load the table into a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Jahresdurchschnitt der Mitarbeiterzahl</td><td>139</td></tr><tr><td>Gesamtvergütung ?</td><td>EUR 15.315.952</td></tr><tr><td>Fixe Vergütung</td><td>EUR 13.151.856</td></tr><tr><td>Variable Vergütung</td><td>EUR 2.164.096</td></tr><tr><td>davon: Carried Interest</td><td>EURO</td></tr><tr><td>Gesamtvergütung für Senior Management ®</td><td>EUR 1.468.434</td></tr><tr><td>Gesamtvergütung für sonstige Risikoträger</td><td>EUR 324.229</td></tr><tr><td>Gesamtvergütung für Mitarbeiter mit Kontrollfunktionen</td><td>EUR 554.046</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(table.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Jahresdurchschnitt der Mitarbeiterzahl ', '139 '],\n",
       " ['Gesamtvergütung ? ', 'EUR 15.315.952 '],\n",
       " ['Fixe Vergütung ', 'EUR 13.151.856 '],\n",
       " ['Variable Vergütung ', 'EUR 2.164.096 '],\n",
       " ['davon: Carried Interest ', 'EURO '],\n",
       " ['Gesamtvergütung für Senior Management ® ', 'EUR 1.468.434 '],\n",
       " ['Gesamtvergütung für sonstige Risikoträger ', 'EUR 324.229 '],\n",
       " ['Gesamtvergütung für Mitarbeiter mit Kontrollfunktionen ', 'EUR 554.046 ']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jahresdurchschnitt der Mitarbeiterzahl  139  \\n Gesamtvergütung ?  EUR 15.315.952  \\n Fixe Vergütung  EUR 13.151.856  \\n Variable Vergütung  EUR 2.164.096  \\n davon: Carried Interest  EURO  \\n Gesamtvergütung für Senior Management ®  EUR 1.468.434  \\n Gesamtvergütung für sonstige Risikoträger  EUR 324.229  \\n Gesamtvergütung für Mitarbeiter mit Kontrollfunktionen  EUR 554.046  \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go deeper down the rabbit hole. A `Table` has cells and we can even get the text of one particular cell. Note that the output list is not sorted by row or column. You have to do it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox',\n",
       " <CellType.BODY>,\n",
       " <CellType.COLUMN_HEADER>,\n",
       " <CellType.COLUMN_NUMBER>,\n",
       " <CellType.COLUMN_SPAN>,\n",
       " <CellType.HEADER>,\n",
       " 'np_image',\n",
       " <CellType.PROJECTED_ROW_HEADER>,\n",
       " <Relationships.READING_ORDER>,\n",
       " <CellType.ROW_HEADER>,\n",
       " <CellType.ROW_NUMBER>,\n",
       " <CellType.ROW_SPAN>,\n",
       " <CellType.SPANNING>,\n",
       " 'text',\n",
       " 'words'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = table.cells[0]\n",
    "cell.get_attribute_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column number: 1 \n",
      " row_number: 8 \n",
      " text: Gesamtvergütung für Mitarbeiter mit Kontrollfunktionen \n",
      " annotation_id: e631e4bc-4740-335f-8618-699bd19a822f\n"
     ]
    }
   ],
   "source": [
    "print(f\"column number: {cell.column_number} \\n row_number: {cell.row_number} \\n text: {cell.text} \\n annotation_id: {cell.annotation_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not down yet, we have a list of words that is responsible to generate the text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox',\n",
       " <WordType.BLOCK>,\n",
       " <WordType.CHARACTER_TYPE>,\n",
       " <WordType.CHARACTERS>,\n",
       " <WordType.HANDWRITTEN>,\n",
       " 'np_image',\n",
       " <WordType.PRINTED>,\n",
       " 'reading_order',\n",
       " <WordType.TAG>,\n",
       " <WordType.TEXT_LINE>,\n",
       " <WordType.TOKEN_CLASS>,\n",
       " <WordType.TOKEN_TAG>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = cell.words[0]\n",
    "word.get_attribute_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reading order determines the string position of the word characters in a cell segment. \n",
    "\n",
    "When inferring the reading order of a page we therefore have to distinguish between high and low level reading orders: A high level reading order where layout segments such as `title`, `text` or `cell` are being involved and a low word level reading order where `word`s have to be arranged into some narrative text.  \n",
    "\n",
    "Let's look at some more attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " characters: Gesamtvergütung \n",
      " reading order: 1 \n",
      " token class: None\n"
     ]
    }
   ],
   "source": [
    "print(f\" characters: {word.characters} \\n reading order: {word.reading_order} \\n token class: {word.token_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and reading\n",
    "\n",
    "You can use the `save` method to save the result of the analyzer in a `.json` file. Setting `image_to_json=True` you will also save image as b64 encoding in the file. Beware, the files are quite large then. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.save(image_to_json=True, path=\"/home/janis/Downloads/test.json\") #path=\"/path/to/dir/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having saved the results you can easily parse the file into the `Page` format without loosing any information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = dd.Page.from_file(file_path=\"/home/janis/Downloads/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Page` object is read-only and even though you can change the value it will not be persisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word.token_class = \"ORG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might look like that the string has been saved however, this is something that is being added by iPython and will not be persisted\n",
    "in any means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ORG'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.token_class #  __repr__ of the base object does carry <WordType.token_class> information.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no easy way yet to modify results. In tutorial **Diving deeper into the data structure** we will show how you can do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to go from here\n",
    "\n",
    "If you want to get a deeper understanding how a pipeline is composed, we suggest to look at the [pipeline notebook](./Pipelines.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd_pt_033",
   "language": "python",
   "name": "dd_pt_033"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
