{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "Let's now take a closer look at pipelines. We will be using the **deep**doctection analyzer as an example. \n",
    "\n",
    "A pipeline is built as a sequence of tasks. These tasks are called pipeline components, pipeline backbones or services.\n",
    "\n",
    "![pipelines](./pics/dd_overview_pipeline.png)\n",
    "\n",
    "Once a pipeline is defined, images or documents can be processed. These are either pure image files (like JPG, PNG, TIFF) or PDF files. PDF files are read and processed page by page. Each PDF page is converted into a numpy array under the hood. \n",
    "\n",
    "We do not want to go into detail about the data structure at this point. If you want more information, please refer to the [data structure notebook](./Data_structure.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdoctection as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the **deep**doctection analyzer. \n",
    "\n",
    "![pipeline](./pics/dd_pipeline.png)\n",
    "\n",
    "The default construction consists of several pipeline components: \n",
    "\n",
    "- Layout analysis (object detection)\n",
    "- Cell analysis in table regions (object detection)\n",
    "- Row and column analysis in table regions (object detection)\n",
    "- Table segmentation \n",
    "- Table segmentation refinement\n",
    "- OCR with Tesseract\n",
    "- Assignment of words to layout segments\n",
    "- Reading order of words within layout segments and reading order of layout segments.\n",
    "\n",
    "Therefore in total, three object detectors and one OCR are loaded.\n",
    "\n",
    "## Configuration\n",
    "\n",
    "![config](./pics/conf_dd_one_yaml.png)\n",
    "\n",
    "We see while initializing a configuration in the logs of the analyzer. The configuration is saved in a `.yaml` file. You can find this file in the .cache dir of **deep**doctection.\n",
    "\n",
    "You can use the `.yaml` file to replace one model with e.g. a model trained on your own data. The tutorial [**Analyzer_Configuration.ipynb**](./Analyzer_Configuration.ipynb) will show you where you need to pay attention when changing the `.yaml` file.\n",
    "\n",
    "In [this tutorial](./Running_pre_trained_models_from_third_party_libraries.ipynb) we will show you how to add a model to the `ModelCatalog` and change the model in the `.yaml` file so that you can use model from third party libraries, that run layout detection models with Detectron2.\n",
    "\n",
    "## Pipeline components\n",
    "\n",
    "Having a pipeline, you can list the components with `get_pipeline_info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'image_weights_layout_d2_model_0829999_layout_inf_only.pt',\n",
       " 1: 'sub_image_weights_item_d2_model_1639999_item_inf_only.pt',\n",
       " 2: 'sub_image_weights_cell_d2_model_1849999_cell_inf_only.pt',\n",
       " 3: 'table_segment',\n",
       " 4: 'table_segment_refine',\n",
       " 5: 'text_extract_tesseract',\n",
       " 6: 'matching',\n",
       " 7: 'text_order'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.get_pipeline_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'table_segment'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.get_pipeline_info(position=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not want to process any text extraction you can set `config_overwrite=[\"USE_OCR=False\"]` which gives you a shorter pipeline with fewer backbones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer(config_overwrite=[\"USE_OCR=False\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `config_overwrite` option allows to overwrite every argument specified in the `.yaml` file. E.g. you can overwrite `SEGMENTATION.ASSIGNMENT_RULE` simply by `config_overwrite=[\"SEGMENTATION.ASSIGNMENT_RULE=True\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'image_weights_layout_d2_model_0829999_layout_inf_only.pt',\n",
       " 1: 'sub_image_weights_item_d2_model_1639999_item_inf_only.pt',\n",
       " 2: 'sub_image_weights_cell_d2_model_1849999_cell_inf_only.pt',\n",
       " 3: 'table_segment',\n",
       " 4: 'table_segment_refine'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.get_pipeline_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have access to pipeline components via `pipe_component_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<deepdoctection.pipe.layout.ImageLayoutService at 0x7fbb7edc85e0>,\n",
       " <deepdoctection.pipe.cell.SubImageLayoutService at 0x7fbbd11b68b0>,\n",
       " <deepdoctection.pipe.cell.SubImageLayoutService at 0x7fbb7c335fd0>,\n",
       " <deepdoctection.pipe.segment.TableSegmentationService at 0x7fbb7c335dc0>,\n",
       " <deepdoctection.pipe.refine.TableSegmentationRefinementService at 0x7fbb7c3c2190>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.pipe_component_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout detection models\n",
    "\n",
    "The `ImageLayoutService` is responsible to detect the coarse layout structure over a full image. It has an object\n",
    "detector, which can be either a Tensorpack or a Detectron2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_layout_service = analyzer.pipe_component_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepdoctection.extern.d2detect.D2FrcnnDetector at 0x7fbb817bb040>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_layout_service.predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a list of all categories that a model is able to detect. Moreover, you will find a unique description of each model in your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LayoutType.text>,\n",
       " <LayoutType.title>,\n",
       " <LayoutType.list>,\n",
       " <LayoutType.table>,\n",
       " <LayoutType.figure>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_layout_service.predictor.possible_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights_layout_d2_model_0829999_layout_inf_only.pt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_layout_service.predictor.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_service = analyzer.pipe_component_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LayoutType.row>, <LayoutType.column>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_service.predictor.possible_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights_item_d2_model_1639999_item_inf_only.pt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_service.predictor.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR and matching words to layout segments\n",
    "\n",
    "Let's re-load the analyzer again, now with OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matching services maps words to layout segments by overlapping rules.  In order to do so, we need to specify what layout segments we want to consider.\n",
    "\n",
    "```yaml\n",
    "WORD_MATCHING:\n",
    "  PARENTAL_CATEGORIES:\n",
    "    - text\n",
    "    - title\n",
    "    - list\n",
    "    - cell\n",
    "    - column_header\n",
    "    - projected_row_header\n",
    "    - spanning\n",
    "    - row_header\n",
    "  RULE:  ioa\n",
    "  THRESHOLD:  0.6\n",
    "```\n",
    "\n",
    "In this situation we do not consider `figure` as valid layout section and neglect any overlapping of a word with a `figure` segment. Of course, this can be changed by adding `figure` to the list of `parent_categories` or in `WORD_MATCHING.PARENTAL_CATEGORIES` in the `.yaml` file.\n",
    "\n",
    "What is going to happen with so called orphan words, e.g. words with no overlapping with any layout segment? They simply have no anchor and will be ignored unless we force to process them as well. We will come to this point later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_service = analyzer.pipe_component_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_categories: ['text', 'title', 'list', 'cell', 'column_header', 'projected_row_header', 'spanning', 'row_header'], child_categories: word\n"
     ]
    }
   ],
   "source": [
    "print(f\"parent_categories: {match_service.parent_categories}, child_categories: {match_service.child_categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a matching rule and a threshold to specifiy. We also need to choose whether we want to assign a word to \n",
    "multiple layout sections. When setting `max_parent_only=True` we assign the word to the layout section with the largest overlapping. Otherwise note, that the word might be considered twice. Changing `max_parent_only` from the `.yaml` is not provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching_rule: ioa \n",
      " match_threshold: 0.6 \n",
      " max_parent_only: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"matching_rule: {match_service.matching_rule} \\n match_threshold: {match_service.threshold} \\n max_parent_only: {match_service.max_parent_only}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading order\n",
    "\n",
    "In the last step, words and layout segments must be arranged to create continuous text. This all takes place in \n",
    "the component `TextOrderService`.\n",
    "\n",
    "Words that are assigned to layout segments are grouped into lines. Lines are read from top to bottom. \n",
    "Auxiliary columns are formed to sort the layout segments. These auxiliary columns are then grouped into contiguous blocks that span vertically across the page. Then the blocks are arranged so that adjacent columns in the contiguous blocks are read from left to right, and the contiguous blocks are read from top to bottom. \n",
    "\n",
    "![pipelines](./pics/dd_connected_blocks.png)\n",
    "\n",
    "\n",
    "This order is, of course, completely arbitrary and will not result in the expected reading order for many layout compositions. \n",
    "\n",
    "An additional difficulty may be that the layout detection is not sufficiently precise and the algorithm returns a questionable reading order. This should always be kept in mind!\n",
    "\n",
    "`TextOrderService` has four important parameters: `text_container`, `text_block_categories`, `floating_text_block_categories` and `include_residual_text_container`. \n",
    "\n",
    "`text_container` must contain the category that contains characters, e.g. `word`. \n",
    "\n",
    "`text_block_categories` contains all layout segments to which words have been added and which must be ordered.\n",
    "\n",
    "`floating_text_block_categories` contains the text blocks to be included in the floating text. For example, it can be discussed whether tables should be included in the body text. In this configuration they are not included in the text. \n",
    "\n",
    "Let's get back to the orphan words: If we set `include_residual_text_container = False`, these words will not receive a `reading_order` and will be ignored in text output.\n",
    "\n",
    "If, on the other hand, we set `include_residual_text_container = True`, they will be grouped and combined into lines and included to the text output. Thus no words are lost. This is an important configuration and you'll likely need to change it.\n",
    "\n",
    "We refer to [this page](https://deepdoctection.readthedocs.io/en/latest/tutorials/layout_parsing_structure) for more detailed information about layout parsing and text ordering.\n",
    "\n",
    "Let's have a look how the text order configs are reflected in the `.yaml`.\n",
    "\n",
    "```yaml\n",
    "TEXT_ORDERING:\n",
    "  TEXT_BLOCK_CATEGORIES:\n",
    "    - title\n",
    "    - text\n",
    "    - list\n",
    "    - cell\n",
    "    - column_header\n",
    "    - projected_row_header\n",
    "    - spanning\n",
    "    - row_header\n",
    "  FLOATING_TEXT_BLOCK_CATEGORIES:\n",
    "    - title\n",
    "    - text\n",
    "    - list\n",
    "  INCLUDE_RESIDUAL_TEXT_CONTAINER: False\n",
    "  STARTING_POINT_TOLERANCE: 0.005\n",
    "  BROKEN_LINE_TOLERANCE: 0.003\n",
    "  HEIGHT_TOLERANCE: 2.0\n",
    "  PARAGRAPH_BREAK: 0.035\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_order_service = analyzer.pipe_component_list[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_container: word \n",
      " floating_text_block_categories: [<LayoutType.title>, <LayoutType.text>, <LayoutType.list>] \n",
      " text_block_categories: [<LayoutType.title>, <LayoutType.text>, <LayoutType.list>, <LayoutType.cell>, <CellType.column_header>, <CellType.projected_row_header>, <CellType.spanning>, <CellType.row_header>] \n",
      " include_residual_text_container: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"text_container: {text_order_service.text_container} \\n floating_text_block_categories: {text_order_service.floating_text_block_categories} \\n text_block_categories: {text_order_service.text_block_categories} \\n include_residual_text_container: {text_order_service.include_residual_text_container}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output structure\n",
    "\n",
    "There is a last step in a pipeline that prepares all information gathered from the different into a consumable class, the `Page` class. The `PageParsingService` is optional and should only be processed if you want to analyze the output.\n",
    "\n",
    "For a deeper understanding of the connection between `Page` and `Image`, we refer to the [data structure notebook](./Data_structure.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyzer.analyze(path=\"path/to/doc.pdf\", output=\"image\")  # output = \"image\" will skip PageParsingService. But default value is \"page\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that the `PageParsingService` is saved in a separate attribute and not part of `analyzer.pipe_component_list`. The `PageParsingService` shares some common parameters with the `TextOrderService`\n",
    "and it is recommended to use the same configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_parser = analyzer.page_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_container: word \n",
      " floating_text_block_categories: [<LayoutType.title>, <LayoutType.text>, <LayoutType.list>] \n",
      " include_residual_text_container: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"text_container: {page_parser.text_container} \\n floating_text_block_categories: {page_parser.floating_text_block_categories} \\n include_residual_text_container: {page_parser.include_residual_text_container}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
